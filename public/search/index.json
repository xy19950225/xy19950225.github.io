[{"categories":["文档"],"contents":"了解如何简单配置 Jupyter Notebook。\nJupyter 配置文件 配置文件，顾名思义就是可以修改Jupyter各种配置的文件。想要修改Jupyter那些默认的配置选项，就需要在配置文件jupyter_notebook_config.py中修改相应配置选项的属性。\n这个配置文件一开始并不存在，需要手动生成。方式很简单，在命令行输入jupyter notebook --generate-config并执行，配置文件就创建好了，它的位置是在C:\\Users\\Administrator\\.jupyter\\中。\n然后我们去c盘主目录下打开.jupyter文件夹，就能找到配置文件：jupyter_notebook_config.py配置文件是关键，后面都要用到的。\n1. 更改默认工作目录 一般情况下，Jupyter的默认工作目录为C:\\Users\\Administrator\\，这样很不清爽，而且不便于管理项目，所以常需要在其他盘建立一个独立的Jupyter工作目录文件。前面提到配置文件jupyter_notebook_config.py，工作目录就在这个里面修改。\n 用记事本打开配置文件jupyter_notebook_config.py； Crtl + F组合键找到c.NotebookApp.notebook_dir元素，删掉前面的注释#； 在后面的单引号里输入要设置的目录路径（注意双斜杠），保存关闭；例如：c.NotebookApp.notebook_dir = \u0026quot;E:\\\\jupyter_notebook\u0026quot; 修改快捷键，在win开始菜单中找到jupyter notebook快捷图标，右击选择属性，删除目标值最后的 “%USERPROFILE%/”，点击确定退出。  经过这四个步骤，工作目录就修改好了，这时候不管你是通过快捷键还是命令行进入Jupyter Notebook，都能看到最新设置的目录，干净清爽。\n2.更改默认浏览器 很多小伙伴有自己的浏览器偏好，希望Jupyter运行在经常使用的那个浏览器上。\n更改Jupyter默认浏览器也比较简单，以设置chrome浏览器为例：\n 找到chrome.exe文件的安装路径，复制该路径。例如：u'C:\\\\Program Files (x86)\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe'查找方式？右键chorme图标，打开文件所在位置，如下图：  用记事本打开配置文件jupyter_notebook_config.py； Crtl + F组合键找到c.NotebookApp.browser元素； 在找到记录的下方添加以下代码（注意替换为你的chrome.exe路径）：  1 2 3  import webbrowser webbrowser.register(\u0026#39;chrome\u0026#39;, None, webbrowser.GenericBrowser(u\u0026#39;C:\\\\Program Files (x86)\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe\u0026#39;)) c.NotebookApp.browser = \u0026#39;chrome\u0026#39;   保存文件。这样就大功告成了，重新启动Jupyter，就会在新设定的浏览器上运行。\n3. 设置登录密码 假如你对自己的Jupyter目录很敏感，不想让别人轻易使用，那么可以设置登录密码。步骤如下：\n 用记事本打开配置文件jupyter_notebook_config.py； Crtl + F组合键找到c.NotebookApp.allow_password_change元素，修改为：NotebookApp.allow_password_change=False，并且删掉前面的注释#，保存文件； 回到windows命令行，运行jupyter notebook password，按照提示输入新密码（注意这里的密码是不显示的）；   可以看到上一步生成了一个json文件，保存在.jupyter文件夹里，和配置文件一个位置。这个json文件保存了密码生成的一段哈希值。找到该文件并打开，复制这段哈希值。 再一次打开配置文件jupyter_notebook_config.py； Crtl + F组合键找到c.NotebookApp.password元素，将前面的哈希值添加到后面，并且删掉前面的注释#，保存文件；示例：c.NotebookApp.password = u'sha1:67c9e60bb8b6:9ffede0825894254b2e042ea597d771089e11aed' 到这里全部设置好了，重启Jupyter，就可以输入新密码登录。  4.安装扩展插件 Jupyter让很多人喜欢的原因在于它提供了丰富的插件，包括显示代码执行时间、生成目录、显示变量名、代码块折叠等各种让你舒适的功能。\n使用插件前，必须要安装扩展nbextensions。\n全程在命令行安装，步骤如下:\n 安装nbextensions 执行pip install jupyter_contrib_nbextensions; 安装javascript and css files 执行jupyter contrib nbextension install --user; 安装configurator 执行pip install jupyter_nbextensions_configurator 重启 Jupyter Notebook， 能看到nbextension 标签  Conda 常用命令 1. 获取版本号 1 2  conda --version conda -V   2. 获取帮助 1 2  conda --help conda -h   查看某一命令的帮助，如update命令及remove命令\n1 2  conda --help update conda --help remove   3. 更新管理 更新conda，保持conda最新：\n1  conda update conda   更新anaconda\n1  conda update anaconda   更新Python\n1  conda update python   假设当前环境是python3.6，conda会将python升级为3.6x系列的当前最新版本\n4. 环境管理 创建新环境\n1  conda create -n \u0026#39;环境名\u0026#39; python=\u0026#39;版本号\u0026#39;   卸载环境\n1  conda remove -n \u0026#39;环境名\u0026#39; --all   查看所有环境\n1  conda info -e   激活指定环境\n1  source activate \u0026#39;环境名\u0026#39;   退出当前环境\n1  source deactivate   5. 包管理 安装包\n1 2  conda install \u0026#39;包的名字\u0026#39; conda install \u0026#39;包的名字\u0026#39;=\u0026#39;版本号\u0026#39; eg: conda install tensorflow=1.10   更新包\n1 2 3  conda update \u0026#39;包的名字\u0026#39; #更新所有包 conda update --all   搜索包(目的是查看可获得的版本)\n1  conda search \u0026#39;包的名字\u0026#39; eg: conda search tensorflow   列出当前环境所有包\n1  conda list   查看指定环境所有包\n1  conda list -n \u0026#39;环境名\u0026#39;   删除环境中的某个包\n1  conda remove -n \u0026#39;环境名\u0026#39; \u0026#39;包的名字\u0026#39;   踩坑 问题01 Jupyter Notebook：kernel error 已解决 问题描述 Jupyter Notebook出现kernel error 当时用Anaconda安装多个版本的Python的时候，时常由于安装和卸载多次Python导致Juoyter notebook不可用。常常导致如下结果\n1 2 3 4 5 6 7 8 9  File”//anaconda/lib/python2.7/site-packages/jupyter_client/manager.py”, line 190, in _launch_kernel return launch_kernel(kernel_cmd, **kw) File “//anaconda/lib/python2.7/site-packages/jupyter_client/launcher.py”, line 123, in launch_kernel proc = Popen(cmd, **kwargs) File “//anaconda/lib/python2.7/subprocess.py”, line 710, in init errread, errwrite) File “//anaconda/lib/python2.7/subprocess.py”, line 1335, in _execute_child raise child_exception OSError: [Errno 2] No such file or director   解决方案  运行python -m ipykernel install --user重新安装内核 如果有多个内核，先运行conda create -n python2 python=2，为Python2.7设置Anaconda变量，在Anacoda下使用activate pyhton2切换python环境 重启jupyter notebook即可  小技巧 查看安装的内核和位置\n1  jupyter kernelspec list   进入安装内核目录打开 kernel.json 文件，查看Python编译器的路径\n问题02 参考  Getting started with conda https://conda.io/projects/conda/en/latest/user-guide/getting-started.html Command reference https://docs.conda.io/projects/conda/en/latest/commands.html Anaconda 镜像使用帮助 https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/ Conda常用命令整理 https://zhengyujie.cn/2257.html Conda 常用命令的整理 https://morooi.cn/2019/anaconda/  ","permalink":"https://xy19950225.github.io/2020-11-13-jupyter-notebook-%E9%85%8D%E7%BD%AE/","tags":["Anaconda","Jupyter Notebook"],"title":"Jupyter Notebook 配置"},{"categories":["刷题"],"contents":"这篇文章主要整理部分 LeeCode 数据库练习题。\n1 前言 本文主要整理 LeeCode 数据库练习，内容通常包含以下几个部分：题目简述、重要知识点、解题思路、逻辑步骤和正确的 SQL 代码。\n最后向在评论区分享经验的广大网友致谢！\n2 正文 2.1 简单 176. 第二高的薪水  题目描述：\n编写一个 SQL 查询，获取 Employee 表中第二高的薪水（Salary）\n   Id Salary     1 100   2 200   3 300    例如上述 Employee 表，SQL 查询应该返回 200 作为第二高的薪水。 如果不存在第二高的薪水，那么查询应返回 NULL\n   SecondHighestSalary     200    解题方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # 方法一：使用子查询和 LIMIT 子句 # 此方法可适用于求第 N 高的薪水，且数据越复杂，速度优势越明显 SELECT (SELECT DISTINCT salary FROM employee ORDER BY salary DESC LIMIT 1,1) AS SecondHighestSalary; # 方法二：使用 IFNULL 和 LIMIT 子句 SELECT IFNULL( (SELECT DISTINCT salary FROM employee ORDER BY salary DESC LIMIT 1,1),NULL) AS SecondHighestSalary; # 方法三：使用子查询和 MAX() 函数 SELECT MAX(salary) AS SecondHighestSalary FROM employee WHERE salary \u0026lt; (SELECT MAX(salary) FROM employee);   596. 超过5名学生的课  题目描述：\n有一个 courses 表 ，有 student (学生) 和 class (课程)，请列出所有超过或等于 5 名学生的课。例如，courses 表：\n   student class     A Math   B English   C Math   D Biology   E Math   F Computer   G Math   H Math   I Math    应该输出:\n   class     Math    提示：学生在每个课中不应被重复计算\n解题方法：\n1 2 3 4 5  # 方法：使用 GROUP BY 和 HAVING SELECT class FROM courses GROUP BY class HAVING COUNT(DISTINCT student) \u0026gt;=5;   197. 上升的温度  题目描述：\n给定一个 Weather 表，编写一个 SQL 查询，来查找与之前（昨天的）日期相比温度更高的所有日期的 Id\n   Id(INT) RecordDate(DATE) Temperature(INT)     1 2015-01-01 10   2 2015-01-02 25   3 2015-01-03 20   4 2015-01-04 30    例如，根据上述给定的 Weather 表格，返回如下 Id:\n   Id     2   4    解题方法：\n1 2 3 4 5 6 7 8 9 10 11 12  # 方法一：使用 JOIN 和 DATEDIFF() 函数 SELECT a.id AS id FROM weather a JOIN weather b ON DATEDIFF(a.recorddate,b.recorddate)=1 AND a.temperature \u0026gt; b.temperature; # 方法二：使用 WHERE 和 DATEDIFF() 函数 SELECT a.id FROM weather a, weather b WHERE DATEDIFF(a.recorddate,b.recorddate)=1 AND a.temperature \u0026gt; b.temperature;   2.2 中等 177. 第N高的薪水  题目描述：\n编写一个 SQL 查询，获取 Employee 表中第 n 高的薪水（Salary）\n   Id Salary     1 100   2 200   3 300    例如上述 Employee 表，n = 2 时，应返回第二高的薪水 200；如果不存在第 n 高的薪水，那么查询应返回 NULL\n   getNthHighestSalary(2)     200    解题方法：\n1 2 3 4 5 6 7 8 9 10 11  CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INT BEGIN SET N = N-1; RETURN ( # Write your MySQL query statement below. SELECT DISTINCT salary FROM employee ORDER BY salary DESC LIMIT N,1 ); END   184. 部门工资最高的员工  题目描述：\nEmployee 表包含所有员工信息，每个员工有其对应的 Id, Salary 和 DepartmentId\n   Id Name Salary DepartmentId     1 Joe 70000 1   2 Jim 90000 1   3 Henry 80000 2   4 Sam 60000 2   5 Max 90000 1    Department 表包含公司所有部门的信息\n   Id Name     1 IT   2 Sales    编写一个 SQL 查询，找出每个部门工资最高的员工。对于上述表，您的 SQL 查询应返回以下行（行的顺序无关紧要）\n   Department Employee Salary     IT Max 90000   IT Jim 90000   Sales Henry 80000    解释：Max 和 Jim 在 IT 部门的工资都是最高的，Henry 在销售部的工资最高\n解题方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # 错误写法 SELECT d.name AS Department, e.name AS Employee, MAX(e.salary) AS Salary FROM employee e JOIN department d ON e.departmentid=d.id GROUP BY Department,Employee,Salary; # 正确写法 # 方法：使用 JOIN 和 IN 语句 SELECT d.name AS Department, e.name AS Employee, e.salary AS Salary FROM employee e JOIN department d ON e.departmentid = d.id WHERE (e.departmentid , e.salary) IN (SELECT departmentid, MAX(salary) FROM employee GROUP BY departmentid ) ;   180. 连续出现的数字  题目描述：\n编写一个 SQL 查询，查找所有至少连续出现三次的数字\n   Id Num     1 1   2 1   3 1   4 2   5 1   6 2   7 2    例如，给定上面的 Logs 表， 1 是唯一连续出现至少三次的数字\n   ConsecutiveNums     1    解题方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  # 方法一：用 DISTINCT 和 WHERE 语句 SELECT DISTINCT a.num AS ConsecutiveNums FROM Logs a ,Logs b , Logs c WHERE b.id = a.id + 1 AND c.id = b.id + 1 AND b.num = a.num AND c.num = b.num; # 方法二: 用 DISTINCT 和 JOIN 语句 # 比方法一执行速度更快 SELECT DISTINCT a.num AS ConsecutiveNums FROM logs a LEFT JOIN logs b ON b.id = a.id + 1 LEFT JOIN logs c ON c.id = b.id + 1 WHERE b.num = a.num AND c.num = b.num; # 上述两种方法有点投机取巧，如果 ID 不连续，连续出现 N 次？ # 方法三： 用窗口函数 ROW_NUMBER() OVER # 参考大佬的思路 SELECT DISTINCT num AS ConsecutiveNums FROM (SELECT num,COUNT(*) AS num_count FROM (SELECT id, num, ROW_NUMBER() OVER(ORDER BY id) - ROW_NUMBER() OVER(PARTITION BY num ORDER BY id) AS orde FROM logs ) AS w GROUP BY num,orde) AS s WHERE num_count \u0026gt;=3;   178. 分数排名  题目描述：\n编写一个 SQL 查询来实现分数排名，如果两个分数相同，则两个分数排名（Rank）相同\n请注意，平分后的下一个名次应该是下一个连续的整数值；换句话说，名次之间不应该有“间隔”\n   Id Score     1 3.50   2 3.65   3 4.00   4 3.85   5 4.00   6 3.65    例如，根据上述给定的 Scores 表，你的查询应该返回（按分数从高到低排列）：\n   Score Rank     4.00 1   4.00 1   3.85 2   3.65 3   3.65 3   3.50 4    重要提示：对于 MySQL 解决方案，如果要转义用作列名的保留字，可以在关键字之前和之后使用撇号。例如 Rank\n解题方法：\n1 2 3 4 5  # 用窗口函数 DENSE_RANK() OVER() SELECT score, DENSE_RANK() OVER(ORDER BY score DESC) \u0026#39;Rank\u0026#39; FROM scores;   2.3 困难 185. 部门工资前三高的所有员工  题目描述：\nEmployee 表包含所有员工信息，每个员工有其对应的工号 Id，姓名 Name，工资 Salary 和部门编号 DepartmentId\n   Id Name Salary DepartmentId     1 Joe 85000 1   2 Henry 80000 2   3 Sam 60000 2   4 Max 90000 1   5 Janet 69000 1   6 Randy 85000 1   7 Will 70000 1    Department 表包含公司所有部门的信息：\n   Id Name     1 IT   2 Sales    编写一个 SQL 查询，找出每个部门获得前三高工资的所有员工。例如，根据上述给定的表，查询结果应返回：\n   Department Employee Salary     IT Max 90000   IT Randy 85000   IT Joe 85000   IT Will 70000   Sales Henry 80000   Sales Sam 60000    解释：IT 部门中，Max 获得了最高的工资，Randy 和 Joe 都拿到了第二高的工资，Will 的工资排第三。销售部门（Sales）只有两名员工，Henry 的工资最高，Sam 的工资排第二\n解题方法：\n1 2 3 4 5 6 7 8 9 10 11 12  SELECT department,employee,salary FROM (SELECT d.name AS department, e.name AS employee, e.salary AS salary, e.departmentid, DENSE_RANK() OVER(PARTITION BY departmentid ORDER BY salary DESC) AS rk FROM employee e JOIN department d ON e.departmentid=d.id) AS w WHERE rk \u0026lt;= 3;   601. 体育馆的人流量  题目描述：\nX 市建了一个新的体育馆，每日人流量信息被记录在这三列信息中：序号 (id)、日期 (visit_date)、 人流量 (people)。\n请编写一个查询语句，找出人流量的高峰期。高峰期时，至少连续三行记录中的人流量不少于100。\n例如，表 stadium：\n   id visit_date people     1 2017-01-01 10   2 2017-01-02 109   3 2017-01-03 150   4 2017-01-04 99   5 2017-01-05 145   6 2017-01-06 1455   7 2017-01-07 199   8 2017-01-08 188    对于上面的示例数据，输出为：\n   id visit_date people     5 2017-01-05 145   6 2017-01-06 1455   7 2017-01-07 199   8 2017-01-08 188    提示：\n 每天只有一行记录，日期随着 id 的增加而增加。 体育馆并不是每天都开放的，所以记录中的日期可能会出现断层。  解题方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  # 方法一：使用双层窗口函数，内层窗口函数求分组编号，外层对分组结果记录数求和 SELECT id, visit_date, people FROM (SELECT id, visit_date, people, COUNT(*) OVER(PARTITION BY a) AS b -- 3.获得同一连续组内记录数 FROM (SELECT id, visit_date, people, id-ROW_NUMBER() OVER(ORDER BY visit_date) AS a -- 2.按日期排序 用id-row_number的方式判断是否连续 FROM stadium WHERE people \u0026gt;=100) AS w) AS q -- 1.挑选出人流超过100的天数 WHERE b \u0026gt;=3; # 方法二 SELECT id, visit_date, people FROM (SELECT id, visit_date, people, LAG(people,2) OVER(ORDER BY id) AS pprvpeople, LAG(people,1) OVER(ORDER BY id) AS prvpeople, LEAD(people,1) OVER(ORDER BY id) AS nextpeople, LEAD(people,2) OVER(ORDER BY id) AS nnextpeople FROM stadium) AS people WHERE (people \u0026gt;=100 AND pprvpeople \u0026gt;=100 AND prvpeople \u0026gt;=100) OR (people \u0026gt;=100 AND prvpeople \u0026gt;=100 AND nextpeople \u0026gt;=100) OR (people \u0026gt;=100 AND nextpeople \u0026gt;=100 AND nnextpeople \u0026gt;=100);   262. 行程和用户  题目描述：\nTrips 表中存所有出租车的行程信息。每段行程有唯一键 Id，Client_Id 和 Driver_Id 是 Users 表中 Users_Id 的外键。Status 是枚举类型，枚举成员为 (‘completed’, ‘cancelled_by_driver’, ‘cancelled_by_client’)。\n   Id Client_Id Driver_Id City_Id Status Request_at     1 1 10 1 completed 2013-10-01   2 2 11 1 cancelled_by_driver 2013-10-01   3 3 12 6 completed 2013-10-01   4 4 13 6 cancelled_by_client 2013-10-01   5 1 10 1 completed 2013-10-02   6 2 11 6 completed 2013-10-02   7 3 12 6 completed 2013-10-02   8 2 12 12 completed 2013-10-03   9 3 10 12 completed 2013-10-03   10 4 13 12 cancelled_by_driver 2013-10-03    Users 表存所有用户。每个用户有唯一键 Users_Id。Banned 表示这个用户是否被禁止，Role 则是一个表示（‘client’, ‘driver’, ‘partner’）的枚举类型。\n   Users_Id Banned Role     1 No client   2 Yes client   3 No client   4 No client   10 No driver   11 No driver   12 No driver   13 No driver    写一段 SQL 语句查出 2013 年10 月1日 至 2013 年10 月 3 日期间非禁止用户的取消率。基于上表，你的 SQL 语句应返回如下结果，取消率（Cancellation Rate）保留两位小数。\n取消率的计算方式如下：(被司机或乘客取消的非禁止用户生成的订单数量) / (非禁止用户生成的订单总数)\n   Day Cancellation Rate     2013-10-01 0.33   2013-10-02 0.00   2013-10-03 0.50    解题方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  SELECT T.request_at AS `Day`, ROUND( SUM( IF(T.STATUS = \u0026#39;completed\u0026#39;,0,1) ) / COUNT(T.STATUS), 2 ) AS `Cancellation Rate` FROM Trips AS T JOIN Users AS U1 ON (T.client_id = U1.users_id AND U1.banned =\u0026#39;No\u0026#39;) JOIN Users AS U2 ON (T.driver_id = U2.users_id AND U2.banned =\u0026#39;No\u0026#39;) WHERE T.request_at BETWEEN \u0026#39;2013-10-01\u0026#39; AND \u0026#39;2013-10-03\u0026#39; GROUP BY T.request_at   3 总结 通过这一段时间的练习基本熟悉了 SQL 的常用语句，JOIN 语句和窗口函数在 SQL 中的重要性不言而喻 。后面我将继续学习 SQL 中的窗口函数和 JOIN 语句，Let\u0026rsquo;s go !😀\n","permalink":"https://xy19950225.github.io/2020-11-13-sql-%E5%8A%9B%E6%89%A3%E7%BB%83%E4%B9%A0/","tags":["LeeCode","SQL"],"title":"SQL 力扣练习"},{"categories":["技术"],"contents":"了解如何使用 SQL 窗口函数。\n更新说明  2020-10-10 新增 使用 Hive SQL 的窗口函数进行商务数据分析 2020-10-01 新增 MySQL 窗口函数 2020-10-01 修订 部分文字和排版\n  \r1. 窗口函数的简介 窗口函数是为了实现 OLAP 而添加的标准 SQL 功能，也称为 OLAP 函数（OnLine Analytical Processing 的简称，指 联机分析处理 ），其作用是将表以窗口为单位进行分割，并在其中进行排序。\n😘注意：从 MySQL 8.0 开始支持窗口函数。\n窗口函数和普通聚合函数很容易混淆，二者区别如下：\n 聚合函数是将多条记录聚合为一条；而窗口函数是每条记录都会执行，有几条记录执行完还是几条。 聚合函数也可以用于窗口函数中。  2. 窗口函数的语法 1 2  # [] 中的内容可以省略 \u0026lt;窗口函数\u0026gt; OVER ([PARTITION BY \u0026lt;列清单\u0026gt;] ORDER BY \u0026lt;排序用列清单\u0026gt;)   小结：窗口函数兼具分组和排序两种功能，通过 PARTITION BY 分组后的记录集合称为“窗口”，PARTITION BY 设定排序的对象范围，ORDER BY 指定按照哪一列、何种顺序进行排序。\n说明： PARTITION BY 和 GROUP BY 的区别 ？\nPARTITION BY 返回分组里的每一行数据，GROUP BY 返回分组里的仅一行数据\n3. 窗口函数的类型 一般按照功能划分可将窗口函数分为聚合窗口函数和专门窗口函数（如排名窗口函数）。\n3.1 聚合窗口函数  以当前记录作为基准进行累计，是聚合窗口函数的最大特征\n 指定 “最靠近的 3 行” 作为汇总对象，输入以下测试代码：\n1 2 3 4  # 指定 “最靠近的 3 行” 作为汇总对象 SELECT product_id, product_name, sale_price, AVG (sale_price) OVER (ORDER BY product_id ROWS 2 PRECEDING) AS moving_avg FROM Product;   其结果输出：\n   product_id product_name sale_price moving_avg     0001 T恤衫 1000 1000   0002 打孔器 500 750   0003 运动T恤 4000 1833   0004 菜刀 3000 2500   0005 高压锅 6800 4600   0006 叉子 500 3433   0007 擦菜板 880 2726   0008 圆珠笔 100 493    将当前记录的前后行作为汇总对象，SQL 语句如下：\n1 2 3 4 5  # 将当前记录的前后行作为汇总对象 SELECT product_id, product_name, sale_price, AVG(sale_price) OVER(ORDER BY product_id ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS moving_avg FROM Product;   输出结果：\n   product_id product_name sale_price moving_avg     0001 T恤衫 1000 750   0002 打孔器 500 1833   0003 运动T恤 4000 2500   0004 菜刀 3000 4600   0005 高压锅 6800 3433   0006 叉子 500 2726   0007 擦菜板 880 493   0008 圆珠笔 100 490    😀说明：ROWS 指定框架，PRECEDING 将框架指定为“截止到之前 ~ 行”，FOLLOWING 将框架指定为“截止到之后 ~ 行”\n3.2 排名窗口函数 排名窗口函数测试代码：\n1 2 3 4 5  SELECT product_name, product_type, sale_price, RANK () OVER (ORDER BY sale_price) AS ranking, DENSE_RANK () OVER (ORDER BY sale_price) AS dense_ranking, ROW_NUMBER () OVER (ORDER BY sale_price) AS row_num FROM Product;   结果输出：\n   product_name product_type sale_price ranking dense_ranking row_num     圆珠笔 办公用品 100 1 1 1   叉子 厨房用具 500 2 2 2   打孔器 办公用品 500 2 2 3   擦菜板 厨房用具 880 4 3 4   T恤衫 衣服 1000 5 4 5   菜刀 厨房用具 3000 6 5 6   运动T恤 衣服 4000 7 6 7   高压锅 厨房用具 6800 8 7 8    3.3 MySQL 支持的窗口函数 按照功能划分，可以把 MySQL 支持的窗口函数分为如下几类：\n 序号函数：row_number () /rank () /dense_rank () 分布函数：percent_rank () /cume_dist () 前后函数：lag () /lead () 头尾函数：first_val () /last_val () 其他函数：nth_value () /nfile ()  分布函数 cume_dist ()\n用途：分组内大于等于当前 rank 值的行数 / 分组内总行数。\n应用场景：大于等于当前订单金额的订单比例有多少。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  select rank() over w as row_num, cume_dist() over w as percent, order_id,user_no,amount,create_date from order_info window w as (partition by user_no order by amount desc); +---------+---------+----------+---------+--------+---------------------+ | row_num | percent | order_id | user_no | amount | create_date | +---------+---------+----------+---------+--------+---------------------+ | 1 | 0.2 | 5 | u0001 | 900 | 2018-01-20 00:00:00 | | 2 | 0.4 | 4 | u0001 | 800 | 2018-01-10 00:00:00 | | 3 | 0.8 | 2 | u0001 | 300 | 2018-01-02 00:00:00 | | 3 | 0.8 | 3 | u0001 | 300 | 2018-01-02 00:00:00 | | 5 | 1 | 1 | u0001 | 100 | 2018-01-01 00:00:00 | | 1 | 0.4 | 9 | u0002 | 800 | 2018-01-16 00:00:00 | | 1 | 0.4 | 10 | u0002 | 800 | 2018-01-22 00:00:00 | | 3 | 0.6 | 7 | u0002 | 600 | 2018-01-06 00:00:00 | | 4 | 0.8 | 6 | u0002 | 500 | 2018-01-05 00:00:00 | | 5 | 1 | 8 | u0002 | 300 | 2018-01-10 00:00:00 | +---------+---------+----------+---------+--------+---------------------+   前后函数 lag ()、lead ()\n用途：\n lag (column,n) 获取当前数据行按照某种排序规则的上 n 行数据的某个字段 lead (column,n) 获取当前数据行按照某种排序规则的下 n 行数据的某个字段  应用场景：按照时间排序，获取当前订单的上一笔订单发生时间和下一笔订单发生时间，（可以计算订单的时间上的间隔度或者说买买买的频繁程度）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  select order_id,user_no,amount,create_date, lag(create_date,1) over w \u0026#39;last_transaction_time\u0026#39;, lead(create_date,1) over w \u0026#39;next_transaction_time\u0026#39; from order_info window w as (partition by user_no order by create_date asc); +----------+---------+--------+---------------------+-----------------------+-----------------------+ | order_id | user_no | amount | create_date | last_transaction_time | next_transaction_time | +----------+---------+--------+---------------------+-----------------------+-----------------------+ | 1 | u0001 | 100 | 2018-01-01 00:00:00 | NULL | 2018-01-02 00:00:00 | | 2 | u0001 | 300 | 2018-01-02 00:00:00 | 2018-01-01 00:00:00 | 2018-01-02 00:00:00 | | 3 | u0001 | 300 | 2018-01-02 00:00:00 | 2018-01-02 00:00:00 | 2018-01-10 00:00:00 | | 4 | u0001 | 800 | 2018-01-10 00:00:00 | 2018-01-02 00:00:00 | 2018-01-20 00:00:00 | | 5 | u0001 | 900 | 2018-01-20 00:00:00 | 2018-01-10 00:00:00 | NULL | | 6 | u0002 | 500 | 2018-01-05 00:00:00 | NULL | 2018-01-06 00:00:00 | | 7 | u0002 | 600 | 2018-01-06 00:00:00 | 2018-01-05 00:00:00 | 2018-01-10 00:00:00 | | 8 | u0002 | 300 | 2018-01-10 00:00:00 | 2018-01-06 00:00:00 | 2018-01-16 00:00:00 | | 9 | u0002 | 800 | 2018-01-16 00:00:00 | 2018-01-10 00:00:00 | 2018-01-22 00:00:00 | | 10 | u0002 | 800 | 2018-01-22 00:00:00 | 2018-01-16 00:00:00 | NULL | +----------+---------+--------+---------------------+-----------------------+-----------------------+   头尾函数 first_value ()、last_value ()\n用途：头尾函数可以得到分区中的第一个 / 最后一个指定参数的值。\n应用场景：查询截止到当前订单，按照日期排序第一个订单和最后一个订单的订单金额。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  select order_id,user_no,amount,create_date, first_value(create_date) over w \u0026#39;first_transaction_time\u0026#39;, last_value(create_date) over w \u0026#39;last_transaction_time\u0026#39; from order_info window w as (partition by user_no order by create_date asc); +----------+---------+--------+---------------------+------------------------+-----------------------+ | order_id | user_no | amount | create_date | first_transaction_time | last_transaction_time | +----------+---------+--------+---------------------+------------------------+-----------------------+ | 1 | u0001 | 100 | 2018-01-01 00:00:00 | 2018-01-01 00:00:00 | 2018-01-01 00:00:00 | | 2 | u0001 | 300 | 2018-01-02 00:00:00 | 2018-01-01 00:00:00 | 2018-01-02 00:00:00 | | 3 | u0001 | 300 | 2018-01-02 00:00:00 | 2018-01-01 00:00:00 | 2018-01-02 00:00:00 | | 4 | u0001 | 800 | 2018-01-10 00:00:00 | 2018-01-01 00:00:00 | 2018-01-10 00:00:00 | | 5 | u0001 | 900 | 2018-01-20 00:00:00 | 2018-01-01 00:00:00 | 2018-01-20 00:00:00 | | 6 | u0002 | 500 | 2018-01-05 00:00:00 | 2018-01-05 00:00:00 | 2018-01-05 00:00:00 | | 7 | u0002 | 600 | 2018-01-06 00:00:00 | 2018-01-05 00:00:00 | 2018-01-06 00:00:00 | | 8 | u0002 | 300 | 2018-01-10 00:00:00 | 2018-01-05 00:00:00 | 2018-01-10 00:00:00 | | 9 | u0002 | 800 | 2018-01-16 00:00:00 | 2018-01-05 00:00:00 | 2018-01-16 00:00:00 | | 10 | u0002 | 800 | 2018-01-22 00:00:00 | 2018-01-05 00:00:00 | 2018-01-22 00:00:00 | +----------+---------+--------+---------------------+------------------------+-----------------------+   😱注意：如果不加 order by, 就没有窗口，计算范围是整个分区；如果加上 order by, 默认窗口是 range between unbounded preceding and current row，就是排序后从分区第一行一直到当前行为止。\n由于我们需要求的是每个用户的第一个和最后一个订单，所以这里要指定窗口：从第一行 unbounded preceding 到最后一行 unbounded following。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  select order_id,user_no,amount,create_date, first_value(create_date) over w \u0026#39;first_transaction_time\u0026#39;, last_value(create_date) over w \u0026#39;last_transaction_time\u0026#39; from order_info window w as (partition by user_no order by create_date asc rows between unbounded preceding and unbounded following); +----------+---------+--------+---------------------+------------------------+-----------------------+ | order_id | user_no | amount | create_date | first_transaction_time | last_transaction_time | +----------+---------+--------+---------------------+------------------------+-----------------------+ | 1 | u0001 | 100 | 2018-01-01 00:00:00 | 2018-01-01 00:00:00 | 2018-01-20 00:00:00 | | 2 | u0001 | 300 | 2018-01-02 00:00:00 | 2018-01-01 00:00:00 | 2018-01-20 00:00:00 | | 3 | u0001 | 300 | 2018-01-02 00:00:00 | 2018-01-01 00:00:00 | 2018-01-20 00:00:00 | | 4 | u0001 | 800 | 2018-01-10 00:00:00 | 2018-01-01 00:00:00 | 2018-01-20 00:00:00 | | 5 | u0001 | 900 | 2018-01-20 00:00:00 | 2018-01-01 00:00:00 | 2018-01-20 00:00:00 | | 6 | u0002 | 500 | 2018-01-05 00:00:00 | 2018-01-05 00:00:00 | 2018-01-22 00:00:00 | | 7 | u0002 | 600 | 2018-01-06 00:00:00 | 2018-01-05 00:00:00 | 2018-01-22 00:00:00 | | 8 | u0002 | 300 | 2018-01-10 00:00:00 | 2018-01-05 00:00:00 | 2018-01-22 00:00:00 | | 9 | u0002 | 800 | 2018-01-16 00:00:00 | 2018-01-05 00:00:00 | 2018-01-22 00:00:00 | | 10 | u0002 | 800 | 2018-01-22 00:00:00 | 2018-01-05 00:00:00 | 2018-01-22 00:00:00 | +----------+---------+--------+---------------------+------------------------+-----------------------+   4. 窗口函数的应用场景 下面这篇文章转载自 Jmx\u0026rsquo;s Blog ，原文链接： 使用Hive SQL的窗口函数进行商务数据分析 。\n这篇文章从一个商务分析案例入手，说明 SQL 窗口函数的使用方式。\n通过本文的 5 个需求分析，可以看出 SQL 窗口函数的功能十分强大，不仅能够使我们编写的 SQL 逻辑更加清晰，而且在某种程度上可以简化需求开发。\n转载时，做了一些文字和格式上的修订。\n 使用 Hive SQL 的窗口函数进行商务数据分析 Jmx\u0026rsquo;s Blog  4.0 数据准备 本文主要分析只涉及一张订单表 orders，操作过程在 Hive 中完成，具体数据如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  -- 建表 CREATE TABLE orders( order_id int, customer_id string, city string, add_time string, amount decimal(10,2)); -- 准备数据 INSERT INTO orders VALUES (1,\u0026#34;A\u0026#34;,\u0026#34;上海\u0026#34;,\u0026#34;2020-01-01 00:00:00.000000\u0026#34;,200), (2,\u0026#34;B\u0026#34;,\u0026#34;上海\u0026#34;,\u0026#34;2020-01-05 00:00:00.000000\u0026#34;,250), (3,\u0026#34;C\u0026#34;,\u0026#34;北京\u0026#34;,\u0026#34;2020-01-12 00:00:00.000000\u0026#34;,200), (4,\u0026#34;A\u0026#34;,\u0026#34;上海\u0026#34;,\u0026#34;2020-02-04 00:00:00.000000\u0026#34;,400), (5,\u0026#34;D\u0026#34;,\u0026#34;上海\u0026#34;,\u0026#34;2020-02-05 00:00:00.000000\u0026#34;,250), (5,\u0026#34;D\u0026#34;,\u0026#34;上海\u0026#34;,\u0026#34;2020-02-05 12:00:00.000000\u0026#34;,300), (6,\u0026#34;C\u0026#34;,\u0026#34;北京\u0026#34;,\u0026#34;2020-02-19 00:00:00.000000\u0026#34;,300), (7,\u0026#34;A\u0026#34;,\u0026#34;上海\u0026#34;,\u0026#34;2020-03-01 00:00:00.000000\u0026#34;,150), (8,\u0026#34;E\u0026#34;,\u0026#34;北京\u0026#34;,\u0026#34;2020-03-05 00:00:00.000000\u0026#34;,500), (9,\u0026#34;F\u0026#34;,\u0026#34;上海\u0026#34;,\u0026#34;2020-03-09 00:00:00.000000\u0026#34;,250), (10,\u0026#34;B\u0026#34;,\u0026#34;上海\u0026#34;,\u0026#34;2020-03-21 00:00:00.000000\u0026#34;,600);   4.1 需求1：收入增长 在业务方面，第 m1 个月的收入增长计算如下：100 *（m1-m0）/ m0\n其中，m1 是给定月份的收入，m0 是上个月的收入。因此，从技术上讲，我们需要找到每个月的收入，然后以某种方式将每个月的收入与上一个收入相关联，以便进行上述计算。计算当时如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  WITH monthly_revenue as ( SELECT trunc(add_time,\u0026#39;MM\u0026#39;) as month, sum(amount) as revenue FROM orders GROUP BY 1 ) ,prev_month_revenue as ( SELECT month, revenue, lag(revenue) over (order by month) as prev_month_revenue -- 上一月收入  FROM monthly_revenue ) SELECT month, revenue, prev_month_revenue, round(100.0*(revenue-prev_month_revenue)/prev_month_revenue,1) as revenue_growth FROM prev_month_revenue ORDER BY 1   结果输出：\n   month revenue prev_month_revenue revenue_growth     2020-01-01 650 NULL NULL   2020-02-01 1250 650 92.3   2020-03-01 1500 1250 20    我们还可以按照按城市分组进行统计，查看某个城市某个月份的收入增长情况\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  WITH monthly_revenue as ( SELECT trunc(add_time,\u0026#39;MM\u0026#39;) as month, city, sum(amount) as revenue FROM orders GROUP BY 1,2 ) ,prev_month_revenue as ( SELECT month, city, revenue, lag(revenue) over (partition by city order by month) as prev_month_revenue FROM monthly_revenue ) SELECT month, city, revenue, round(100.0*(revenue-prev_month_revenue)/prev_month_revenue,1) as revenue_growth FROM prev_month_revenue ORDER BY 2,1   结果输出：\n   month city revenue revenue_growth     2020-01-01 上海 450 NULL   2020-02-01 上海 950 111.1   2020-03-01 上海 1000 5.3   2020-01-01 北京 200 NULL   2020-02-01 北京 300 50   2020-03-01 北京 500 66.7    4.2 需求2：累计求和 累计汇总，即当前元素和所有先前元素的总和，如下面的 SQL：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  WITH monthly_revenue as ( SELECT trunc(add_time,\u0026#39;MM\u0026#39;) as month, sum(amount) as revenue FROM orders GROUP BY 1 ) SELECT month, revenue, sum(revenue) over (order by month rows between unbounded preceding and current row) as running_total FROM monthly_revenue ORDER BY 1   结果输出：\n   month revenue running_total     2020-01-01 650 650   2020-02-01 1250 1900   2020-03-01 1500 3400    我们还可以使用下面的组合方式进行分析，SQL 如下：\n1 2 3 4 5 6 7 8 9 10 11 12  SELECT order_id, customer_id, city, add_time, amount, sum(amount) over () as amount_total, -- 所有数据求和  sum(amount) over (order by order_id rows between unbounded preceding and current row) as running_sum, -- 累计求和  sum(amount) over (partition by customer_id order by add_time rows between unbounded preceding and current row) as running_sum_by_customer, avg(amount) over (order by add_time rows between 5 preceding and current row) as trailing_avg -- 滚动求平均 FROM orders ORDER BY 1   结果输出：\n   order_id customer_id city add_time amount amount_total running_sum running_sum_by_customer trailing_avg     1 A 上海 2020-01-01 00:00:00.000000 200 3400 200 200 200   2 B 上海 2020-01-05 00:00:00.000000 250 3400 450 250 225   3 C 北京 2020-01-12 00:00:00.000000 200 3400 650 200 216.666667   4 A 上海 2020-02-04 00:00:00.000000 400 3400 1050 600 262.5   5 D 上海 2020-02-05 00:00:00.000000 250 3400 1300 250 260   5 D 上海 2020-02-05 12:00:00.000000 300 3400 1600 550 266.666667   6 C 北京 2020-02-19 00:00:00.000000 300 3400 1900 500 283.333333   7 A 上海 2020-03-01 00:00:00.000000 150 3400 2050 750 266.666667   8 E 北京 2020-03-05 00:00:00.000000 500 3400 2550 500 316.666667   9 F 上海 2020-03-09 00:00:00.000000 250 3400 2800 250 291.666667   10 B 上海 2020-03-21 00:00:00.000000 600 3400 3400 850     4.3 需求3：处理重复数据 从上面的数据可以看出，存在两条重复的数据**(5,”D”,”上海”,”2020-02-05 00:00:00.000000”,250), (5,”D”,”上海”,”2020-02-05 12:00:00.000000”,300),**显然需要对其进行清洗去重，保留最新的一条数据，SQL 如下：\n我们先进行分组排名，然后保留最新的那条数据即可：\n1 2 3 4 5 6 7  SELECT * FROM ( SELECT *, row_number() over (partition by order_id order by add_time desc) as rank FROM orders ) t WHERE rank=1   结果输出：\n   t.order_id t.customer_id t.city t.add_time t.amount t.rank     1 A 上海 2020-01-01 00:00:00.000000 200 1   2 B 上海 2020-01-05 00:00:00.000000 250 1   3 C 北京 2020-01-12 00:00:00.000000 200 1   4 A 上海 2020-02-04 00:00:00.000000 400 1   5 D 上海 2020-02-05 12:00:00.000000 300 1   6 C 北京 2020-02-19 00:00:00.000000 300 1   7 A 上海 2020-03-01 00:00:00.000000 150 1   8 E 北京 2020-03-05 00:00:00.000000 500 1   9 F 上海 2020-03-09 00:00:00.000000 250 1   10 B 上海 2020-03-21 00:00:00.000000 600 1    经过上面的清洗过程，对数据进行了去重。重新计算上面的需求1，正确 SQL 脚本为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  WITH orders_cleaned as ( SELECT * FROM ( SELECT *, row_number() over (partition by order_id order by add_time desc) as rank FROM orders )t WHERE rank=1 ) ,monthly_revenue as ( SELECT trunc(add_time,\u0026#39;MM\u0026#39;) as month, sum(amount) as revenue FROM orders_cleaned GROUP BY 1 ) ,prev_month_revenue as ( SELECT month, revenue, lag(revenue) over (order by month) as prev_month_revenue FROM monthly_revenue ) SELECT month, revenue, round(100.0*(revenue-prev_month_revenue)/prev_month_revenue,1) as revenue_growth FROM prev_month_revenue ORDER BY 1   结果输出：\n   month revenue revenue_growth     2020-01-01 650 NULL   2020-02-01 1000 53.8   2020-03-01 1500 50    将清洗后的数据创建成视图，方便以后使用\n1 2 3 4 5 6 7 8 9 10 11 12 13  CREATE VIEW orders_cleaned AS SELECT order_id, customer_id, city, add_time, amount FROM ( SELECT *, row_number() over (partition by order_id order by add_time desc) as rank FROM orders )t WHERE rank=1   4.4 需求4：分组取TopN 分组取 TopN 是最长见的 SQL 窗口函数使用场景，下面的 SQL 是计算每个月份的 top2 订单金额，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  WITH orders_ranked as ( SELECT trunc(add_time,\u0026#39;MM\u0026#39;) as month, *, row_number() over (partition by trunc(add_time,\u0026#39;MM\u0026#39;) order by amount desc, add_time) as rank FROM orders_cleaned ) SELECT month, order_id, customer_id, city, add_time, amount FROM orders_ranked WHERE rank \u0026lt;=2 ORDER BY 1   4.5 需求5：重复购买行为 下面的 SQL 计算重复购买率：重复购买的人数/总人数*100%以及第一笔订单金额与第二笔订单金额之间的典型差额:avg(第二笔订单金额/第一笔订单金额)\n1 2 3 4 5 6 7 8 9 10  WITH customer_orders as ( SELECT *, row_number() over (partition by customer_id order by add_time) as customer_order_n, lag(amount) over (partition by customer_id order by add_time) as prev_order_amount FROM orders_cleaned ) SELECT round(100.0*sum(case when customer_order_n=2 then 1 end)/count(distinct customer_id),1) as repeat_purchases,-- 重复购买率 avg(case when customer_order_n=2 then 1.0*amount/prev_order_amount end) as revenue_expansion -- 重复购买较上次购买差异，第一笔订单金额与第二笔订单金额之间的典型差额 FROM customer_orders   结果输出：\n   orders_cleaned.order_id orders_cleaned.customer_id orders_cleaned.city orders_cleaned.add_time orders_cleaned.amount customer_order_n prev_order_amount     1 A 上海 2020-01-01 00:00:00.000000 200 1 NULL   4 A 上海 2020-02-04 00:00:00.000000 400 2 200   7 A 上海 2020-03-01 00:00:00.000000 150 3 400   2 B 上海 2020-01-05 00:00:00.000000 250 1 NULL   10 B 上海 2020-03-21 00:00:00.000000 600 2 250   3 C 北京 2020-01-12 00:00:00.000000 200 1 NULL   6 C 北京 2020-02-19 00:00:00.000000 300 2 200   5 D 上海 2020-02-05 12:00:00.000000 300 1 NULL   8 E 北京 2020-03-05 00:00:00.000000 500 1 NULL   9 F 上海 2020-03-09 00:00:00.000000 250      最终结果输出：\n   repeat_purchases revenue_expansion     50 1.9666666666666668    5. 参考  SQL 基础教程（第 2 版）- MICK (作者) 孙淼 , 罗勇 (译者) MySQL 窗口函数 https://tding.top/archives/c6e31643.html 使用 Hive SQL 的窗口函数进行商务数据分析 Jmx\u0026rsquo;s Blog  ","permalink":"https://xy19950225.github.io/2020-11-13-sql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%E6%80%BB%E7%BB%93/","tags":["SQL","窗口函数"],"title":"SQL 窗口函数总结"},{"categories":["文档"],"contents":"了解如何在 LoveIt 主题中快速, 直观地创建和组织内容.\n1 内容组织 以下是一些方便你清晰管理和生成文章的目录结构建议:\n 保持博客文章存放在 content/posts 目录, 例如: content/posts/我的第一篇文章.md 保持简单的静态页面存放在 content 目录, 例如: content/about.md 保持图片之类的媒体资源存放在 static 目录, 例如: static/images/screenshot.png  2 前置参数 Hugo 允许你在文章内容前面添加 yaml, toml 或者 json 格式的前置参数.\n注意\n不是所有的以下前置参数都必须在你的每篇文章中设置. 只有在文章的参数和你的 网站设置 中的 page 部分不一致时才有必要这么做.\n","permalink":"https://xy19950225.github.io/2020-11-13-%E4%B8%BB%E9%A2%98%E6%96%87%E6%A1%A3-%E5%86%85%E5%AE%B9/","tags":["配置","Markdown"],"title":"主题文档 - 内容"},{"categories":[],"contents":"2020-11-17 2020-11-17 2020-11-17 导航栏添加Font Awesome 图标\n2020-11-15 添加搜索功能\n2020-11-13 将Even 主题更换为 LoveIt 主题\n2020-10-01 将博客迁移到 Hugo ，采用 Even 主题，并部署到 GitHub Pages 上\n2020-07-13 使用 Material for MkDocs 搭建个人博客\n","permalink":"https://xy19950225.github.io/about/","tags":[],"title":"关于"},{"categories":[],"contents":"B站  ","permalink":"https://xy19950225.github.io/movie/","tags":[],"title":"电影"},{"categories":[],"contents":"网易云  ","permalink":"https://xy19950225.github.io/music/","tags":[],"title":"音乐"},{"categories":null,"contents":"","permalink":"https://xy19950225.github.io/search/","tags":null,"title":"Search"}]