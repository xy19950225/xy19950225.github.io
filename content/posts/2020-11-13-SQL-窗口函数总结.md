---
title: "SQL 窗口函数总结"
date: 2020-11-13T16:30:05+08:00
lastmod: 2020-11-13T16:30:05+08:00
draft: false

tags: ["SQL", "窗口函数"]
categories: ["技术"]
hiddenFromHomePage: false

featuredImage: ""
featuredImagePreview: ""

toc: true
autoCollapseToc: true
math: true
lightgallery: true
linkToMarkdown: true
---

了解如何使用 SQL 窗口函数。

<!--more-->

{{% admonition 更新说明 更新说明 %}} 

2020-10-10 新增 [使用 Hive SQL 的窗口函数进行商务数据分析](https://jiamaoxiang.top/2020/09/07/%E4%BD%BF%E7%94%A8Hive-SQL%E7%9A%84%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%E8%BF%9B%E8%A1%8C%E5%95%86%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/)

2020-10-01 新增 [MySQL 窗口函数](https://tding.top/archives/c6e31643.html) 

2020-10-01 修订 部分文字和排版

 {{% /admonition %}}




## 1. 窗口函数的简介



**窗口函数**是为了实现 OLAP 而添加的标准 SQL 功能，也称为 OLAP 函数（OnLine Analytical Processing 的简称，指 [**联机分析处理**](https://zh.wikipedia.org/wiki/%E7%B7%9A%E4%B8%8A%E5%88%86%E6%9E%90%E8%99%95%E7%90%86) ），其作用是将表以窗口为单位进行分割，并在其中进行排序。

😘**注意**：从 **MySQL 8.0** 开始支持窗口函数。

窗口函数和普通聚合函数很容易混淆，二者区别如下：

- **聚合函数是将多条记录聚合为一条；而窗口函数是每条记录都会执行，有几条记录执行完还是几条**。
- 聚合函数也可以用于窗口函数中。

## 2. 窗口函数的语法

```sql
# [] 中的内容可以省略
<窗口函数> OVER ([PARTITION BY <列清单>] ORDER BY <排序用列清单>)
```

小结：窗口函数兼具分组和排序两种功能，通过 `PARTITION BY` 分组后的记录集合称为“窗口”，`PARTITION BY` 设定排序的对象范围，`ORDER BY` 指定按照哪一列、何种顺序进行排序。

说明： PARTITION BY 和 GROUP BY 的区别 ？

 `PARTITION BY` 返回分组里的每一行数据，`GROUP BY` 返回分组里的仅一行数据




## 3. 窗口函数的类型

一般按照功能划分可将窗口函数分为聚合窗口函数和专门窗口函数（如排名窗口函数）。



### 3.1 聚合窗口函数

> 以**当前记录**作为基准进行**累计**，是聚合窗口函数的最大特征

指定 “最靠近的 3 行” 作为汇总对象，输入以下测试代码：

```sql
# 指定 “最靠近的 3 行” 作为汇总对象
SELECT product_id, product_name, sale_price,
	AVG (sale_price) OVER (ORDER BY product_id ROWS 2 PRECEDING) AS moving_avg
FROM Product;
```

其结果输出：


| product_id | product_name | sale_price | moving_avg |
| :--------: | :----------: | :--------: | :--------: |
| 0001       | T恤衫        | 1000        | 1000       |
| 0002       | 打孔器        | 500         | 750        |
| 0003       | 运动T恤       | 4000        | 1833       |
| 0004       | 菜刀          | 3000       | 2500       |
| 0005       | 高压锅        | 6800       | 4600       |
| 0006       | 叉子          | 500        | 3433       |
| 0007       | 擦菜板        | 880        | 2726       |
| 0008       | 圆珠笔        | 100        | 493        |

将当前记录的前后行作为汇总对象，SQL 语句如下：

```sql
# 将当前记录的前后行作为汇总对象
SELECT product_id, product_name, sale_price,
	AVG(sale_price) OVER(ORDER BY product_id 
	ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS moving_avg 
FROM Product;
```

输出结果：

| product_id | product_name | sale_price | moving_avg |
| :--------: | :----------: | :--------: | :--------: |
|       0001 | T恤衫        |       1000 |        750 |
|       0002 | 打孔器       |        500 |       1833 |
|       0003 | 运动T恤      |       4000 |       2500 |
|       0004 | 菜刀         |       3000 |       4600 |
|       0005 | 高压锅       |       6800 |       3433 |
|       0006 | 叉子         |        500 |       2726 |
|       0007 | 擦菜板       |        880 |        493 |
|       0008 | 圆珠笔       |        100 |        490 |



😀说明：`ROWS` 指定框架，`PRECEDING` 将框架指定为“截止到之**前** ~ 行”，`FOLLOWING`  将框架指定为“截止到之**后** ~ 行”



### 3.2 排名窗口函数



排名窗口函数测试代码：

```sql
SELECT product_name, product_type, sale_price,
	RANK () OVER (ORDER BY sale_price) AS ranking,
	DENSE_RANK () OVER (ORDER BY sale_price) AS dense_ranking,
	ROW_NUMBER () OVER (ORDER BY sale_price) AS row_num
FROM Product;
```

结果输出：

| product_name | product_type | sale_price | ranking | dense_ranking | row_num |
| :----------: | :----------: | :--------: | :-----: | :-----------: | :-----: |
| 圆珠笔       | 办公用品     |        100 |       1 |             1 |       1 |
| 叉子         | 厨房用具     |        500 |       2 |             2 |       2 |
| 打孔器       | 办公用品     |        500 |       2 |             2 |       3 |
| 擦菜板       | 厨房用具     |        880 |       4 |             3 |       4 |
| T恤衫        | 衣服         |       1000 |       5 |             4 |       5 |
| 菜刀         | 厨房用具     |       3000 |       6 |             5 |       6 |
| 运动T恤      | 衣服         |       4000 |       7 |             6 |       7 |
| 高压锅       | 厨房用具     |       6800 |       8 |             7 |       8 |



### 3.3 MySQL 支持的窗口函数

按照功能划分，可以把 MySQL 支持的窗口函数分为如下几类：

- 序号函数：row_number () /rank () /dense_rank ()
- 分布函数：percent_rank () /cume_dist ()
- 前后函数：lag () /lead ()
- 头尾函数：first_val () /last_val ()
- 其他函数：nth_value () /nfile ()

分布函数 cume_dist ()

用途：分组内大于等于当前 rank 值的行数 / 分组内总行数。

应用场景：大于等于当前订单金额的订单比例有多少。

```sql
select 
rank() over w as row_num,
cume_dist() over w as percent,
order_id,user_no,amount,create_date
from order_info
window w as (partition by user_no order by amount desc);
+---------+---------+----------+---------+--------+---------------------+
| row_num | percent | order_id | user_no | amount | create_date         |
+---------+---------+----------+---------+--------+---------------------+
|       1 |     0.2 |        5 | u0001   |    900 | 2018-01-20 00:00:00 |
|       2 |     0.4 |        4 | u0001   |    800 | 2018-01-10 00:00:00 |
|       3 |     0.8 |        2 | u0001   |    300 | 2018-01-02 00:00:00 |
|       3 |     0.8 |        3 | u0001   |    300 | 2018-01-02 00:00:00 |
|       5 |       1 |        1 | u0001   |    100 | 2018-01-01 00:00:00 |
|       1 |     0.4 |        9 | u0002   |    800 | 2018-01-16 00:00:00 |
|       1 |     0.4 |       10 | u0002   |    800 | 2018-01-22 00:00:00 |
|       3 |     0.6 |        7 | u0002   |    600 | 2018-01-06 00:00:00 |
|       4 |     0.8 |        6 | u0002   |    500 | 2018-01-05 00:00:00 |
|       5 |       1 |        8 | u0002   |    300 | 2018-01-10 00:00:00 |
+---------+---------+----------+---------+--------+---------------------+
```

前后函数 lag ()、lead ()

用途：

- lag (column,n) 获取当前数据行按照某种排序规则的上 n 行数据的某个字段
- lead (column,n) 获取当前数据行按照某种排序规则的下 n 行数据的某个字段

应用场景：按照时间排序，获取当前订单的上一笔订单发生时间和下一笔订单发生时间，（可以计算订单的时间上的间隔度或者说买买买的频繁程度）。

```sql
select 
order_id,user_no,amount,create_date,
lag(create_date,1) over w 'last_transaction_time',
lead(create_date,1) over w 'next_transaction_time'
from order_info
window w as (partition by user_no order by create_date asc);
+----------+---------+--------+---------------------+-----------------------+-----------------------+
| order_id | user_no | amount | create_date         | last_transaction_time | next_transaction_time |
+----------+---------+--------+---------------------+-----------------------+-----------------------+
|        1 | u0001   |    100 | 2018-01-01 00:00:00 | NULL                  | 2018-01-02 00:00:00   |
|        2 | u0001   |    300 | 2018-01-02 00:00:00 | 2018-01-01 00:00:00   | 2018-01-02 00:00:00   |
|        3 | u0001   |    300 | 2018-01-02 00:00:00 | 2018-01-02 00:00:00   | 2018-01-10 00:00:00   |
|        4 | u0001   |    800 | 2018-01-10 00:00:00 | 2018-01-02 00:00:00   | 2018-01-20 00:00:00   |
|        5 | u0001   |    900 | 2018-01-20 00:00:00 | 2018-01-10 00:00:00   | NULL                  |
|        6 | u0002   |    500 | 2018-01-05 00:00:00 | NULL                  | 2018-01-06 00:00:00   |
|        7 | u0002   |    600 | 2018-01-06 00:00:00 | 2018-01-05 00:00:00   | 2018-01-10 00:00:00   |
|        8 | u0002   |    300 | 2018-01-10 00:00:00 | 2018-01-06 00:00:00   | 2018-01-16 00:00:00   |
|        9 | u0002   |    800 | 2018-01-16 00:00:00 | 2018-01-10 00:00:00   | 2018-01-22 00:00:00   |
|       10 | u0002   |    800 | 2018-01-22 00:00:00 | 2018-01-16 00:00:00   | NULL                  |
+----------+---------+--------+---------------------+-----------------------+-----------------------+
```



头尾函数 first_value ()、last_value ()

用途：头尾函数可以得到分区中的第一个 / 最后一个指定参数的值。

应用场景：查询截止到当前订单，按照日期排序第一个订单和最后一个订单的订单金额。

```sql
select 
order_id,user_no,amount,create_date,
first_value(create_date) over w 'first_transaction_time',
last_value(create_date) over w 'last_transaction_time'
from order_info
window w as (partition by user_no order by create_date asc);
+----------+---------+--------+---------------------+------------------------+-----------------------+
| order_id | user_no | amount | create_date         | first_transaction_time | last_transaction_time |
+----------+---------+--------+---------------------+------------------------+-----------------------+
|        1 | u0001   |    100 | 2018-01-01 00:00:00 | 2018-01-01 00:00:00    | 2018-01-01 00:00:00   |
|        2 | u0001   |    300 | 2018-01-02 00:00:00 | 2018-01-01 00:00:00    | 2018-01-02 00:00:00   |
|        3 | u0001   |    300 | 2018-01-02 00:00:00 | 2018-01-01 00:00:00    | 2018-01-02 00:00:00   |
|        4 | u0001   |    800 | 2018-01-10 00:00:00 | 2018-01-01 00:00:00    | 2018-01-10 00:00:00   |
|        5 | u0001   |    900 | 2018-01-20 00:00:00 | 2018-01-01 00:00:00    | 2018-01-20 00:00:00   |
|        6 | u0002   |    500 | 2018-01-05 00:00:00 | 2018-01-05 00:00:00    | 2018-01-05 00:00:00   |
|        7 | u0002   |    600 | 2018-01-06 00:00:00 | 2018-01-05 00:00:00    | 2018-01-06 00:00:00   |
|        8 | u0002   |    300 | 2018-01-10 00:00:00 | 2018-01-05 00:00:00    | 2018-01-10 00:00:00   |
|        9 | u0002   |    800 | 2018-01-16 00:00:00 | 2018-01-05 00:00:00    | 2018-01-16 00:00:00   |
|       10 | u0002   |    800 | 2018-01-22 00:00:00 | 2018-01-05 00:00:00    | 2018-01-22 00:00:00   |
+----------+---------+--------+---------------------+------------------------+-----------------------+
```



😱注意：如果不加 `order by`, 就没有窗口，计算范围是整个分区；如果加上 `order by`, 默认窗口是 `range between unbounded preceding and current row`，就是排序后从分区第一行一直到当前行为止。

由于我们需要求的是每个用户的第一个和最后一个订单，所以这里要指定窗口：从第一行 `unbounded preceding` 到最后一行 `unbounded following`。

```sql
select 
order_id,user_no,amount,create_date,
first_value(create_date) over w 'first_transaction_time',
last_value(create_date) over w 'last_transaction_time'
from order_info
window w as (partition by user_no order by create_date asc rows between unbounded preceding and unbounded following);
+----------+---------+--------+---------------------+------------------------+-----------------------+
| order_id | user_no | amount | create_date         | first_transaction_time | last_transaction_time |
+----------+---------+--------+---------------------+------------------------+-----------------------+
|        1 | u0001   |    100 | 2018-01-01 00:00:00 | 2018-01-01 00:00:00    | 2018-01-20 00:00:00   |
|        2 | u0001   |    300 | 2018-01-02 00:00:00 | 2018-01-01 00:00:00    | 2018-01-20 00:00:00   |
|        3 | u0001   |    300 | 2018-01-02 00:00:00 | 2018-01-01 00:00:00    | 2018-01-20 00:00:00   |
|        4 | u0001   |    800 | 2018-01-10 00:00:00 | 2018-01-01 00:00:00    | 2018-01-20 00:00:00   |
|        5 | u0001   |    900 | 2018-01-20 00:00:00 | 2018-01-01 00:00:00    | 2018-01-20 00:00:00   |
|        6 | u0002   |    500 | 2018-01-05 00:00:00 | 2018-01-05 00:00:00    | 2018-01-22 00:00:00   |
|        7 | u0002   |    600 | 2018-01-06 00:00:00 | 2018-01-05 00:00:00    | 2018-01-22 00:00:00   |
|        8 | u0002   |    300 | 2018-01-10 00:00:00 | 2018-01-05 00:00:00    | 2018-01-22 00:00:00   |
|        9 | u0002   |    800 | 2018-01-16 00:00:00 | 2018-01-05 00:00:00    | 2018-01-22 00:00:00   |
|       10 | u0002   |    800 | 2018-01-22 00:00:00 | 2018-01-05 00:00:00    | 2018-01-22 00:00:00   |
+----------+---------+--------+---------------------+------------------------+-----------------------+
```



## 4. 窗口函数的应用场景

下面这篇文章转载自 [Jmx's Blog](https://jiamaoxiang.top/)，原文链接： [使用Hive SQL的窗口函数进行商务数据分析](https://jiamaoxiang.top/2020/09/07/%E4%BD%BF%E7%94%A8Hive-SQL%E7%9A%84%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%E8%BF%9B%E8%A1%8C%E5%95%86%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/) 。

这篇文章从一个商务分析案例入手，说明 SQL 窗口函数的使用方式。

通过本文的 5 个需求分析，可以看出 SQL 窗口函数的功能十分强大，不仅能够使我们编写的 SQL 逻辑更加清晰，而且在某种程度上可以简化需求开发。

转载时，做了一些文字和格式上的修订。

> 使用 Hive SQL 的窗口函数进行商务数据分析 [Jmx's Blog](https://jiamaoxiang.top/2020/09/07/%E4%BD%BF%E7%94%A8Hive-SQL%E7%9A%84%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%E8%BF%9B%E8%A1%8C%E5%95%86%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/)

### 4.0 数据准备

本文主要分析只涉及一张订单表 orders，操作过程在 Hive 中完成，具体数据如下：

```sql
-- 建表
CREATE TABLE orders(
    order_id int,
    customer_id string,
    city string,
    add_time string,
    amount decimal(10,2));

-- 准备数据                              
INSERT INTO orders VALUES
(1,"A","上海","2020-01-01 00:00:00.000000",200),
(2,"B","上海","2020-01-05 00:00:00.000000",250),
(3,"C","北京","2020-01-12 00:00:00.000000",200),
(4,"A","上海","2020-02-04 00:00:00.000000",400),
(5,"D","上海","2020-02-05 00:00:00.000000",250),
(5,"D","上海","2020-02-05 12:00:00.000000",300),
(6,"C","北京","2020-02-19 00:00:00.000000",300),
(7,"A","上海","2020-03-01 00:00:00.000000",150),
(8,"E","北京","2020-03-05 00:00:00.000000",500),
(9,"F","上海","2020-03-09 00:00:00.000000",250),
(10,"B","上海","2020-03-21 00:00:00.000000",600);
```

### 4.1 需求1：收入增长

在业务方面，第 m1 个月的收入增长计算如下：**100 \*（m1-m0）/ m0**

其中，m1 是给定月份的收入，m0 是上个月的收入。因此，从技术上讲，我们需要找到每个月的收入，然后以某种方式将每个月的收入与上一个收入相关联，以便进行上述计算。计算当时如下：

```sql
WITH
monthly_revenue as (
    SELECT
    trunc(add_time,'MM') as month,
    sum(amount) as revenue
    FROM orders
    GROUP BY 1
)
,prev_month_revenue as (
    SELECT 
    month,
    revenue,
    lag(revenue) over (order by month) as prev_month_revenue -- 上一月收入
    FROM monthly_revenue
)
SELECT 
  month,
  revenue,
  prev_month_revenue,
  round(100.0*(revenue-prev_month_revenue)/prev_month_revenue,1) as revenue_growth
FROM prev_month_revenue
ORDER BY 1
```

结果输出：

| month      | revenue | prev_month_revenue | revenue_growth |
| :--------: | :-----: | :----------------: | :------------: |
| 2020-01-01 | 650     | NULL               | NULL           |
| 2020-02-01 | 1250    | 650                | 92.3           |
| 2020-03-01 | 1500    | 1250               | 20             |

我们还可以按照按城市分组进行统计，查看某个城市某个月份的收入增长情况

```sql
WITH
monthly_revenue as (
    SELECT
     trunc(add_time,'MM') as month,
    city,
    sum(amount) as revenue
    FROM orders
    GROUP BY 1,2
)
,prev_month_revenue as (
    SELECT 
    month,
    city,
    revenue,
    lag(revenue) over (partition by city order by month) as prev_month_revenue
    FROM monthly_revenue
)
SELECT 
month,
city,
revenue,
round(100.0*(revenue-prev_month_revenue)/prev_month_revenue,1) as revenue_growth
FROM prev_month_revenue
ORDER BY 2,1
```

结果输出：

| month      | city | revenue | revenue_growth |
| :--------: | :--: | :-----: | :------------: |
| 2020-01-01 | 上海 | 450     | NULL           |
| 2020-02-01 | 上海 | 950     | 111.1          |
| 2020-03-01 | 上海 | 1000    | 5.3            |
| 2020-01-01 | 北京 | 200     | NULL           |
| 2020-02-01 | 北京 | 300     | 50             |
| 2020-03-01 | 北京 | 500     | 66.7           |

### 4.2 需求2：累计求和

累计汇总，即当前元素和所有先前元素的总和，如下面的 SQL：

```sql
WITH
monthly_revenue as (
    SELECT
    trunc(add_time,'MM') as month,
    sum(amount) as revenue
    FROM orders
    GROUP BY 1
)
SELECT 
month,
revenue,
sum(revenue) over (order by month rows between unbounded preceding and current row) as running_total
FROM monthly_revenue
ORDER BY 1
```

结果输出：

| month      | revenue | running_total |
| :--------: | :-----: | :-----------: |
| 2020-01-01 | 650     | 650           |
| 2020-02-01 | 1250    | 1900          |
| 2020-03-01 | 1500    | 3400          |

我们还可以使用下面的组合方式进行分析，SQL 如下：

```sql
SELECT
   order_id,
   customer_id,
   city,
   add_time,
   amount,
   sum(amount) over () as amount_total, -- 所有数据求和
   sum(amount) over (order by order_id rows between unbounded preceding and current row) as running_sum, -- 累计求和
   sum(amount) over (partition by customer_id order by add_time rows between unbounded    preceding and current row) as running_sum_by_customer, 
   avg(amount) over (order by add_time rows between 5 preceding and current row) as  trailing_avg -- 滚动求平均
FROM orders
ORDER BY 1
```

结果输出：

| order_id | customer_id | city | add_time                   | amount | amount_total | running_sum | running_sum_by_customer | trailing_avg |
| :------: | :---------: | :--: | :------------------------: | :----: | :----------: | :---------: | :---------------------: | :----------: |
| 1        | A           | 上海 | 2020-01-01 00:00:00.000000 | 200    | 3400         | 200         | 200                     | 200          |
| 2        | B           | 上海 | 2020-01-05 00:00:00.000000 | 250    | 3400         | 450         | 250                     | 225          |
| 3        | C           | 北京 | 2020-01-12 00:00:00.000000 | 200    | 3400         | 650         | 200                     | 216.666667   |
| 4        | A           | 上海 | 2020-02-04 00:00:00.000000 | 400    | 3400         | 1050        | 600                     | 262.5        |
| 5        | D           | 上海 | 2020-02-05 00:00:00.000000 | 250    | 3400         | 1300        | 250                     | 260          |
| 5        | D           | 上海 | 2020-02-05 12:00:00.000000 | 300    | 3400         | 1600        | 550                     | 266.666667   |
| 6        | C           | 北京 | 2020-02-19 00:00:00.000000 | 300    | 3400         | 1900        | 500                     | 283.333333   |
| 7        | A           | 上海 | 2020-03-01 00:00:00.000000 | 150    | 3400         | 2050        | 750                     | 266.666667   |
| 8        | E           | 北京 | 2020-03-05 00:00:00.000000 | 500    | 3400         | 2550        | 500                     | 316.666667   |
| 9        | F           | 上海 | 2020-03-09 00:00:00.000000 | 250    | 3400         | 2800        | 250                     | 291.666667   |
| 10       | B           | 上海 | 2020-03-21 00:00:00.000000 | 600    | 3400         | 3400        | 850                     |              |

### 4.3 需求3：处理重复数据

从上面的数据可以看出，存在两条重复的数据**(5,”D”,”上海”,”2020-02-05 00:00:00.000000”,250),
(5,”D”,”上海”,”2020-02-05 12:00:00.000000”,300),**显然需要对其进行清洗去重，保留最新的一条数据，SQL 如下：

我们先进行分组排名，然后保留最新的那条数据即可：

```sql
SELECT *
FROM (
    SELECT *,
    row_number() over (partition by order_id order by add_time desc) as rank
    FROM orders
) t
WHERE rank=1
```

结果输出：

| t.order_id | t.customer_id | t.city | t.add_time                 | t.amount | t.rank |
| :--------: | :-----------: | :----: | :------------------------: | :------: | :----: |
| 1          | A             | 上海   | 2020-01-01 00:00:00.000000 | 200      | 1      |
| 2          | B             | 上海   | 2020-01-05 00:00:00.000000 | 250      | 1      |
| 3          | C             | 北京   | 2020-01-12 00:00:00.000000 | 200      | 1      |
| 4          | A             | 上海   | 2020-02-04 00:00:00.000000 | 400      | 1      |
| 5          | D             | 上海   | 2020-02-05 12:00:00.000000 | 300      | 1      |
| 6          | C             | 北京   | 2020-02-19 00:00:00.000000 | 300      | 1      |
| 7          | A             | 上海   | 2020-03-01 00:00:00.000000 | 150      | 1      |
| 8          | E             | 北京   | 2020-03-05 00:00:00.000000 | 500      | 1      |
| 9          | F             | 上海   | 2020-03-09 00:00:00.000000 | 250      | 1      |
| 10         | B             | 上海   | 2020-03-21 00:00:00.000000 | 600      | 1      |

经过上面的清洗过程，对数据进行了去重。重新计算上面的需求1，正确 SQL 脚本为：

```sql
WITH
orders_cleaned as (
    SELECT *
    FROM (
        SELECT *,
        row_number() over (partition by order_id order by add_time desc) as rank
        FROM orders
    )t
    WHERE rank=1
)
,monthly_revenue as (
    SELECT
    trunc(add_time,'MM') as month,
    sum(amount) as revenue
    FROM orders_cleaned
    GROUP BY 1
)
,prev_month_revenue as (
    SELECT 
    month,
    revenue,
    lag(revenue) over (order by month) as prev_month_revenue
    FROM monthly_revenue
)
SELECT 
month,
revenue,
round(100.0*(revenue-prev_month_revenue)/prev_month_revenue,1) as revenue_growth
FROM prev_month_revenue
ORDER BY 1
```

结果输出：

| month      | revenue | revenue_growth |
| :--------: | :-----: | :------------: |
| 2020-01-01 | 650     | NULL           |
| 2020-02-01 | 1000    | 53.8           |
| 2020-03-01 | 1500    | 50             |

将清洗后的数据创建成视图，方便以后使用

```sql
CREATE VIEW orders_cleaned AS
SELECT
    order_id, 
    customer_id, 
    city, 
    add_time, 
    amount
FROM (
    SELECT *,
    row_number() over (partition by order_id order by add_time desc) as rank
    FROM orders
)t
WHERE rank=1
```

### 4.4 需求4：分组取TopN

分组取 TopN 是最长见的 SQL 窗口函数使用场景，下面的 SQL 是计算每个月份的 top2 订单金额，如下：

```sql
WITH orders_ranked as (
    SELECT
    trunc(add_time,'MM') as month,
    *,
    row_number() over (partition by trunc(add_time,'MM') order by amount desc, add_time) as rank
    FROM orders_cleaned
)
SELECT 
    month,
    order_id,
    customer_id,
    city,
    add_time,
    amount
FROM orders_ranked
WHERE rank <=2
ORDER BY 1
```

### 4.5 需求5：重复购买行为

下面的 SQL 计算重复购买率：重复购买的人数/总人数*100%以及第一笔订单金额与第二笔订单金额之间的典型差额:avg(第二笔订单金额/第一笔订单金额)

```sql
WITH customer_orders as (
    SELECT *,
    row_number() over (partition by customer_id order by add_time) as customer_order_n,
    lag(amount) over (partition by customer_id order by add_time) as prev_order_amount
    FROM orders_cleaned
)
SELECT
round(100.0*sum(case when customer_order_n=2 then 1 end)/count(distinct customer_id),1) as repeat_purchases,-- 重复购买率
avg(case when customer_order_n=2 then 1.0*amount/prev_order_amount end) as revenue_expansion -- 重复购买较上次购买差异，第一笔订单金额与第二笔订单金额之间的典型差额
FROM customer_orders
```

结果输出：

| orders_cleaned.order_id | orders_cleaned.customer_id | orders_cleaned.city | orders_cleaned.add_time    | orders_cleaned.amount | customer_order_n | prev_order_amount |
| :---------------------: | :------------------------: | :-----------------: | :------------------------: | :-------------------: | :--------------: | :---------------: |
| 1                       | A                          | 上海                | 2020-01-01 00:00:00.000000 | 200                   | 1                | NULL              |
| 4                       | A                          | 上海                | 2020-02-04 00:00:00.000000 | 400                   | 2                | 200               |
| 7                       | A                          | 上海                | 2020-03-01 00:00:00.000000 | 150                   | 3                | 400               |
| 2                       | B                          | 上海                | 2020-01-05 00:00:00.000000 | 250                   | 1                | NULL              |
| 10                      | B                          | 上海                | 2020-03-21 00:00:00.000000 | 600                   | 2                | 250               |
| 3                       | C                          | 北京                | 2020-01-12 00:00:00.000000 | 200                   | 1                | NULL              |
| 6                       | C                          | 北京                | 2020-02-19 00:00:00.000000 | 300                   | 2                | 200               |
| 5                       | D                          | 上海                | 2020-02-05 12:00:00.000000 | 300                   | 1                | NULL              |
| 8                       | E                          | 北京                | 2020-03-05 00:00:00.000000 | 500                   | 1                | NULL              |
| 9                       | F                          | 上海                | 2020-03-09 00:00:00.000000 | 250                   |                  |                   |

最终结果输出：

| repeat_purchases | revenue_expansion  |
| :--------------: | :----------------: |
| 50               | 1.9666666666666668 |



## 5. 参考

1. SQL 基础教程（第 2 版）- MICK (作者) 孙淼 , 罗勇 (译者) 
2. MySQL 窗口函数 https://tding.top/archives/c6e31643.html
3. 使用 Hive SQL 的窗口函数进行商务数据分析  [Jmx's Blog](https://jiamaoxiang.top/2020/09/07/%E4%BD%BF%E7%94%A8Hive-SQL%E7%9A%84%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%E8%BF%9B%E8%A1%8C%E5%95%86%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/) 